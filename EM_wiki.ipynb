{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM(Expectation Maximization) algorithm\n",
    "EM 알고리즘은 관측되지 않는 잠재변수(unobserved latent variables)이 존재하는 Probabilistic model에서 MLE(Maximum Likelihood Estimation) 또는 MAP(Maximum A Posteriori) 문제를 풀기 위한 알고리즘 중 하나이다.\n",
    "\n",
    "그렇다면, MLE, MAP에서 사용하던 기존의 방법들을 왜 사용하지 않고 굳이 EM algorithm을 따로 사용하는 것일까? 그 이유는 어떠한 조치를 취하지 않고서는 주어진 probabilistic model을 풀어낼 수 없는 경우가 존재하기 때문이다. \n",
    "\n",
    "이런 경우는 대개 model에 관측되지 않는 잠재변수(unobserved latent variable)가 포함되어 있는 것을 말한다. 즉, 알고 있는 데이터 관측값과 알려지지 않은 parameter(매개변수)에 더불어 잠재변수(latent variable)가 존재하는 것이다. 혹은 매 관측값이 그에 상응하는 잠재변수나 관측되지 않은 값을 가지고 있다고 가정할 수도 있다.\n",
    "\n",
    "MLE를 하는 경우에는, log likelihood function를 미분하여 parameter를 찾을 수 있다. 그러나 풀고자 하는 model이 잠재변수를 포함한다면, 각각의 변수에 대한 식이 서로 얽혀있어서 정확한 해를 구하는 것이 불가능하게 된다. \n",
    "(혹은 풀고자 하는 model에 대한 maximum likelihood를 직접 계산하는 것이 너무 까다로워서 우리가 임의로 설정한 latent variable(hidden variable)을 추가하는 경우일 수도 있다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "EM은 E-step과 M-step의 두 단계로 나뉘어진다. E-step에서는 missing values를 추정하며, M-step에서는 E-step에 의해 채워진 데이터를 가지고 parameter를 최적화한다. parameter가 더 이상 변화하지 않고 수렴하게 될 때까지 E-step과 M-step을 반복하는 방법이 EM algorithm이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "관측할 수 있는 확률변수 $X$, 관측할 수 없는 확률변수 $Z$, 매개변수 $\\theta$가 있을 때, $(X,Z)$에 대한 확률분포(probability distribution)가\n",
    "\n",
    "$\\qquad L(\\theta;X,Z)=p(X,Z|\\theta)$  \n",
    "\n",
    "로 주어져 있을 때, MLE를 계산하고 싶은 경우 likelihood function은 다음과 같이 정의할 수 있다.\n",
    "\n",
    "$\\qquad L(\\theta;X)=p(X|\\theta)=\\sum_{Z}(p(X,Z|\\theta))$  \n",
    "\n",
    "이 수식은 잠재변수(latent variable) $Z$가 취할 수 있는 값의 수에 비례하고, $Z$의 차원이 증가할수록 취할 수 있는 값의 수는 지수적으로 증가하기 때문에 이 수식을 계산하기는 매우 어렵다.  \n",
    "EM algorithm은 다음의 두 단계를 반복하여 likelihood function $L(\\theta;X)$의 MLE를 구한다.\n",
    "\n",
    "E-step: $\\theta^{(t)}$가 주어지며 새로운 $\\theta$를 사용할 때의 ML의 기댓값인 $Q$를 정의한다. 이 때 기댓값을 취하는 확률분포는 $X, \\theta^{(t)}$가 주어졌을 때 $Z$의 조건부 분포이다.\n",
    "\n",
    "$\\qquad Q(\\theta|\\theta^{(t)})=E_{Z|X,\\theta^{(t)}}[logL(\\theta;X,Z)]=\\sum_{Z}p(Z|X,\\theta^{(t)})logL(\\theta;X,Z)$\n",
    "\n",
    "M-step: $Q$를 최대화하는 새로운 parameter $\\theta^{(t+1)}$를 계산한다.\n",
    "\n",
    "$\\qquad Q^{(t+1)}=arg\\max_{\\theta} Q(\\theta|\\theta^{(t)})$\n",
    "\n",
    "EM algorithm은 다양한 모델에 적용 가능하지만, 적용되는 모델은.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
