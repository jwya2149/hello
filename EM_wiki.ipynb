{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM(Expectation Maximization) algorithm\n",
    "EM 알고리즘은 관측되지 않는 잠재변수(unobserved latent variables)이 존재하는 Probabilistic model에서 MLE(Maximum Likelihood Estimation) 또는 MAP(Maximum A Posteriori) 문제를 풀기 위한 알고리즘 중 하나이다.\n",
    "\n",
    "그렇다면, MLE, MAP에서 사용하던 기존의 방법들을 왜 사용하지 않고 굳이 EM algorithm을 따로 사용하는 것일까? 그 이유는 어떠한 조치를 취하지 않고서는 주어진 probabilistic model을 풀어낼 수 없는 경우가 존재하기 때문이다. \n",
    "\n",
    "이런 경우는 대개 model에 관측되지 않는 잠재변수(unobserved latent variable)가 포함되어 있는 것을 말한다. 즉, 알고 있는 데이터 관측값과 알려지지 않은 parameter(매개변수)에 더불어 잠재변수(latent variable)가 존재하는 것이다. 혹은 매 관측값이 그에 상응하는 잠재변수나 관측되지 않은 값을 가지고 있다고 가정할 수도 있다.\n",
    "\n",
    "MLE의 경우에는 log likelihood function를 미분하여 parameter를 찾을 수 있다. 그러나 풀고자 하는 model이 잠재변수를 포함한다면, 각각의 변수에 대한 식이 서로 얽혀있어서 정확한 해를 구하는 것이 불가능하게 된다.  \n",
    "(혹은 풀고자 하는 model에 대한 maximum likelihood를 직접 계산하는 것이 너무 까다로워서 우리가 임의로 설정한 latent variable(hidden variable)을 추가하는 경우일 수도 있다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM algorithm은 굉장히 많은 probabilistic model을 풀기 위해 널리 사용되는 알고리즘 중 하나이며, iterative한 알고리즘이다. Clustering, unsupervised learning 문제를 풀기 위해서도 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM은 E-step과 M-step의 두 단계로 나뉘어진다. E-step에서는 missing values를 추정하며, M-step에서는 E-step에 의해 채워진 데이터를 가지고 parameter를 최적화한다. parameter가 더 이상 변화하지 않고 수렴하게 될 때까지 E-step과 M-step을 반복하는 방법이 EM algorithm이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EM 알고리즘은 예시를 보지 않고서는 이해하기 힘들다. 간단한 예시를 통해 EM algorithm이 어느 때 사용되며 어떤 목적으로 사용되는지 확인해 보자. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예시 참조: http://jaekwangkim.com/articles/2017-02/EM_Algorithm (카이스트 김재광 교수)\n",
    "\n",
    "EM algorithm을 사용해야 하는 상황을 이해하기 위해 영화 추천 시스템을 개발하는 상황을 가정해 보자. 시스템 안에는 K개의 영화가 있고 고객은 돈을 지불하여 영화를 스트리밍으로 볼 수 있는데, 영화 감상이 끝나면 영화에 대한 간단한 추천 여부를 제출해야 한다고 하자. (반드시 추천 혹은 비추천을 선택해야 하며, 강제로 종료할 경우에는 비추천으로 간주한다고 가정하자)  \n",
    "\n",
    "이 회사는 이 추천/비추천 데이터를 가지고 사용자들의 영화 취향을 파악함으로써 사용자들에게 기존 데이터를 바탕으로 그들의 영화 취향에 따라 영화를 추천하는 시스템을 만들고자 한다.  \n",
    "어떻게 추천 시스템을 구축해야 할까?\n",
    "\n",
    "> 이러한 문제는 전형적인 missing data 예측 문제이다.\n",
    "\n",
    "왜냐하면 사용자가 시스템에 있는 모든 영화를 보는 것이 아니기 때문에, 어떤 특정한 사용자의 추천/비추천 기록은 그 사용자가 본 영화에 대해서만 존재하고, 보지 않은 대부분의 영화에 대해서는 아무런 데이터가 없기 때문이다. 어떻게 다른 영화를 추천해야 할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이에 대답하기 위해서는 현재의 고객 데이터로부터 전체 영화들의 선호도 관계를 추정한후\n",
    "\n",
    "$\\qquad P(Y_4=1|Y_1=1,Y_2=0,Y_3=1),$  \n",
    "$\\qquad P(Y_5=1|Y_1=1,Y_2=0,Y_3=1)$  \n",
    "$\\qquad\\qquad $where $ Y_k:$ 영화 $k$의 추천 여부(추천이면 1, 비추천이면 0), $K=5$이며 이 고객은 영화 1, 2, 3을 본 상태인 경우\n",
    "\n",
    "의 conditional probability를 계산하여 둘 중 더 큰 값을 갖는 항목에 해당하는 영화를 추천해주면 되는 것이다. 그리고 이러한 conditional probability를 추정하기 위해서는 EM algorithm을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기에 EM algorithm을 적용하는 과정을 자세히 설명하지는 않겠지만, 여기에서는 특정 사용자가 본 영화가 관측된 data, 보지 않은 영화가 latent variable, 모든 영화에 대한 추천 여부를 parameter라고 여길 수 있을 것이다.\n",
    "\n",
    "$\\qquad parameter:\\qquad\\pi_{abcde}=P(Y_1=a,Y_2=b,Y_3=c,Y_4=d,Y_5=e)$  \n",
    "\n",
    "E-step은 missing value를 추정하는 단계이므로, E-step에서는 특정 사용자에 대해 그 사용자가 보지 않은 영화에 대해서도 추천/비추천 여부의 데이터를 임시로 넣을 것이다. 이렇게 모든 고객에 대해 가상 데이터를 만들어 각 고객에게 모든 가능한 경우의 조합으로 자료를 확장하고 그에 대한 가중치를 구현해 줌으로써 전체 자료에 missing data가 없는 것처럼 만들어주게 된다.\n",
    "이렇게 만들어진 전체 가상 자료를 이용하면 parameter $\\pi_{abcde}$의 추정치를 간단하게 업데이트할 수 있을 것이며, 이렇게 parameter를 업데이트하는 과정이 M-step에 해당할 것이다. \n",
    "\n",
    "E-step과 M-step을 번갈아가면서 parameter가 어떤 값으로 수렴하면 알고리즘이 종료된 것으로, 그 최종값을 가지고 확률을 계산하면 원하는 결과를 얻을 수 있게 되는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n",
    "이번에는 좀 더 간단한 예시를 가지고 직접 EM algorithm을 적용해 보자.\n",
    "예시 참조: https://www.nature.com/articles/nbt1406\n",
    "\n",
    "### A coin-flipping experiment\n",
    "Head와 Tail이 나올 확률이 서로 다른 동전 A와 동전 B가 있다.  \n",
    "$\\qquad \\theta_A:$ A에서 head가 나올 확률, $\\qquad 1-\\theta_A:$ A에서 tail이 나올 확률  \n",
    "$\\qquad \\theta_B:$ B에서 head가 나올 확률, $\\qquad 1-\\theta_B:$ B에서 tail이 나올 확률  \n",
    "이 중 하나의 동전을 여러 번 던져서 head와 tail의 등장 빈도수(확률)를 얻었을 때,  \n",
    "이로부터 내가 던진 동전이 A인지 B인지 어떻게 알 수 있겠는가?  \n",
    "\n",
    "동전 A, 동전 B 중 하나를 무작위로 골라 10번 던지는 과정을 5번 반복하는 상황을 생각해 보자.  \n",
    "여기서 우리의 목표는 $\\theta=(\\theta_A,\\theta_B)$와 어떤 동전을 던졌는지를 추정하는 것이다.  \n",
    "그러나 $\\theta_A$와 $\\theta_B$를 모르며, 어떤 동전을 던졌는지도 모르므로 우리가 아는 관측값은 오직 다음의 5가지 뿐이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Raw.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서, 우리가 EM algorithm을 기준으로 할 때의 data는 다음과 같다.\n",
    "\n",
    "<img src=\"figure1.png\" width=\"380\">\n",
    "\n",
    "만약, 우리가 Z를 알고 있다면 일반적인 MLE를 이용하여 최적의 parameter를 찾을 수 있을 것이다.  \n",
    "$\\qquad argmax_{\\theta}$ $l(\\theta)=\\log p(X,Z;\\theta)$\n",
    "\n",
    "그러나 우리는 Z를 알지 못하므로, 일반적인 MLE로는 parameter를 추정할 수 없다. (incomlete dataset)  \n",
    "만약 각 round마다 어느 동전이 사용되었는지 추정할 수 있는 방법이 있다면, data는 complete해지므로 이 complete dataset에 MLE를 적용할 수 있다. \n",
    "\n",
    "다시 말해보면, 다음과 같다.\n",
    "\n",
    "EM algorithm은 현재의 parameter $\\theta(t)$를 사용하여 missing data의 각 가능한 completion에 대한 확률을 계산한다.  \n",
    "이 확률은 data의 모든 possible completion으로 구성된 weighted training set을 만들기 위해 사용된다.  \n",
    "마지막으로, weighted training example을 처리하는 수정된 MLE을 진행하여 새로운 parameter estimates인 $\\theta^{(t+1)}$을 얻게 된다.  \n",
    "\n",
    "---\n",
    ">E-step: 현재 모델에 주어진 missing data의 completion에 대한 probability distribution을 추측하는 단계  \n",
    "M-step: 이러한 completion을 이용하여 model의 parameter를 다시 추정하는 단계  \n",
    "\n",
    "---\n",
    "E-step이라는 이름은 probability distribution을 명시적으로 형성할 필요 없이 completion에 대해 'Expected' sufficient statistics만 계산하면 되기 때문에 붙여졌으며,  \n",
    "M-step이라는 이름은 model을 reestimate하는 것이 data의 expected log-likelihood를 'Maximization' 한다는 점에서 붙여졌다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 구체적으로 EM algorithm을 진행해 보자.\n",
    "\n",
    "1. 임의로 parameter를 설정한다. $\\theta_A=0.6, \\theta_B=0.5$  \n",
    "2. iterative:  \n",
    "$\\qquad$ 2-1. 각 Round에 대해 Head가 나온 수를 확인한다.  \n",
    "$\\qquad$ 2-2. 그 비율이 각 동전 A, B에서 나왔을 확률을 계산한다.  \n",
    "$\\qquad$ 2-3. Head가 나오는 수의 기댓값을 계산한다.  \n",
    "$\\qquad$ 2-4. (모든 Round에 대해) 이 수들을 기록한다.  \n",
    "$\\qquad$ 2-5. 동전 A, B에 대한 새로운 평균(Head가 나오는 비율)을 다시 계산하여 parameter를 update한다.  \n",
    "$\\qquad$ 2-6. parameter가 어떤 값에 수렴하여 더 이상 변화하지 않으면, iteration을 중단한다.    \n",
    "\n",
    "이제, 각 Round에서 동전 A, B 중 어떤 동전을 던졌을 확률과 각 동전에서 Head가 나올 확률을 알게 되었다.  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이제 계산해 보자. (2-1, 2-2, 2-3은 Round 1을 기준으로만 표시하였다)\n",
    "\n",
    "2-1. 각 Round에 대해 Head가 나온 수를 확인한다.  \n",
    "\n",
    ">Round 1에서는 H가 5번, T가 5번 나왔다. \n",
    "\n",
    "2-2. 그 비율이 각 동전 A, B에서 나왔을 확률을 계산한다.  \n",
    ">$\\theta_A=0.6, \\theta_B=0.55$ 이므로, 동전 A, B에 대해 이렇게 결과가 나왔을 확률은\n",
    "$\\qquad P_A(HTTTHHTHTH)=0.60^5 * 0.40^5 = 0.000796$  \n",
    "$\\qquad P_B(HTTTHHTHTH)=0.50^5 * 0.50^5 = 0.000977$\n",
    "\n",
    "> Normalizing하면,  \n",
    "$\\qquad$ 0.000796 / (0.000796+0.000977) = 0.45 : Round 1에서는 동전 A를 던졌을 확률  \n",
    "$\\qquad$ 0.000977 / (0.000796+0.000977) = 0.55 : Round 1에서는 동전 B를 던졌을 확률  \n",
    "\n",
    "2-3. Head가 나오는 수의 기댓값을 계산한다. \n",
    "> \n",
    "동전 A였다면, Head는 0.45\\*H = 2.2번, Tail은 0.45\\*H = 2.2번  \n",
    "동전 B였다면, Head는 0.55\\*H = 2.8번, Tail은 0.45\\*H = 2.8번\n",
    "\n",
    "2-4. (모든 Round에 대해) 이 수들을 기록한다. \n",
    "<img src=\"2-4.png\" width=\"500\">\n",
    "\n",
    "2-5. 동전 A, B에 대한 새로운 평균(Head가 나오는 비율)을 다시 계산하여 parameter를 update한다.  \n",
    "> \n",
    "동전 A였다면 Head가 총 21.3번, Tail이 8.6번  \n",
    "동전 B였다면 Head가 총 11.7번, Tail이 8.4번  \n",
    "\n",
    "> \n",
    "따라서  \n",
    "$\\qquad \\theta_A=\\frac{21.3}{21.3+8.6} = 0.71$  \n",
    "$\\qquad \\theta_B=\\frac{11.7}{11.7+8.4} = 0.58$  \n",
    "\n",
    "2-6. parameter가 어떤 값에 수렴하여 더 이상 변화하지 않으면, iteration을 중단한다.  \n",
    "> \n",
    "2-1 ~ 2-5의 과정을 반복하면, parameter는 $\\theta_A=0.8$, $\\theta_B=0.52$에 수렴한다.  \n",
    "이렇게 parameter를 찾았으며, 각 Round에서 동전 A 혹은 동전 B를 던졌을 확률은 2-1 ~ 2-2의 과정을 진행하면\n",
    "\n",
    "> \n",
    "Round 1에서는 동전 A를 던졌을 확률: 0.097  \n",
    "Round 1에서는 동전 B를 던졌을 확률: 0.902\n",
    "\n",
    "<img src=\"result_table.png\" width=\"380\">  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사진으로 다시 확인해 보자.  \n",
    "\n",
    "<img src=\"full.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그렇다면, 이 EM algorithm은 기존의 MLE와 어떻게 다른가? MLE를 사용하는 방식을 그림으로 나타내면 다음과 같다. \n",
    "\n",
    "<img src=\"mle.png\" width=\"550\">\n",
    "\n",
    "그림과 같이, MLE의 경우에는 매 Round마다 선택하여 던진 동전이 A인지 B인지 알아야 사용할 수 있으며, 10번씩 던지는 Round를 5번밖에 하지 못했으므로 parameter가 정확하다고 말하기 힘들다  \n",
    "(Round를 훨씬 많이 진행하면 parameter $\\theta$가 EM algorithm으로 구했을 때와 유사한 값이 될 것이다)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제, 이를 python으로 직접 계산하는 코드를 구현해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of EM algorithm in coin-flipping experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter(theta) initialization\n",
    "theta = [0.6, 0.5]\n",
    "\n",
    "# Experiement parameter\n",
    "k = 5 # number of Rounds\n",
    "n = 10 # number of tosses for each round\n",
    "\n",
    "X = [] # number of heads for each round\n",
    "Z = [] # coin type for each round\n",
    "\n",
    "type = 0 # basic example\n",
    "\n",
    "if (type == 0):\n",
    "    print(\"Basic Example\")\n",
    "    X = [5,9,8,4,7]\n",
    "else:\n",
    "    for i in range(k):\n",
    "        print(\"number of Heads at \",i+1, \" round: \", sep='', end='')\n",
    "        x = int(input())\n",
    "        X.append(x)\n",
    "print(\"X:\",X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration of E-step and M-step\n",
    "# Learning parameter theta\n",
    "A_numH = 0\n",
    "A_numT = 0\n",
    "B_numH = 0\n",
    "B_numT = 0\n",
    "    \n",
    "count = 1\n",
    "while(1):\n",
    "    for i in range(k):\n",
    "        # 2-1, 2-2\n",
    "        pA = theta[0]**(X[i]) * ((1-theta[0])**(n-(X[i])))\n",
    "        pB = theta[1]**(X[i]) * ((1-theta[1])**(n-(X[i])))\n",
    "\n",
    "        norm_pA = pA / (pA+pB)\n",
    "        norm_pB = pB / (pA+pB)\n",
    "\n",
    "        # 2-3, 2-4\n",
    "        A_numH += norm_pA * X[i]\n",
    "        A_numT += norm_pA * (n-X[i])\n",
    "        B_numH += norm_pB * X[i]\n",
    "        B_numT += norm_pB * (n-X[i])\n",
    "\n",
    "    # 2-5\n",
    "    new_thetaA = A_numH / (A_numH + A_numT)\n",
    "    new_thetaB = B_numH / (B_numH + B_numT)\n",
    "    \n",
    "    # 2-6\n",
    "    if (abs(new_thetaA - theta[0]) < 0.000001 and abs(new_thetaB - theta[1]) < 0.000001):\n",
    "        print(\"End! iteration count:\", count)\n",
    "        break\n",
    "\n",
    "    theta[0] = new_thetaA\n",
    "    theta[1] = new_thetaB\n",
    "    count += 1\n",
    "    \n",
    "print(\"th_A:\",theta[0], \"th_B:\",theta[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(k):\n",
    "    pA = theta[0]**(X[i]) * ((1-theta[0])**(n-(X[i])))\n",
    "    pB = theta[1]**(X[i]) * ((1-theta[1])**(n-(X[i])))\n",
    "    norm_pA = pA / (pA+pB)\n",
    "    norm_pB = pB / (pA+pB)\n",
    "    print(\"[Round \",i+1, \"]\", sep=\"\")\n",
    "    print(\"    A를 던졌을 확률: \",round(norm_pA,5), \", B를 던졌을 확률: \",round(norm_pB,5), sep=\"\")\n",
    "    print(\"    예상 동전:\", end=\"\")\n",
    "    if (norm_pA > norm_pB):\n",
    "        print(\"A\")\n",
    "    elif (norm_pA < norm_pB):\n",
    "        print(\"B\")\n",
    "    else:\n",
    "        print(\"Parameter의 초기값이 같아서 EM을 적용할 수 없다!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 결과를 위에서 보았던 예시 결과(표)와 비교해 보자.\n",
    "\n",
    "<img src=\"result_table.png\" width=\"380\">\n",
    "\n",
    "확률이 약간 다른 이유는 예시에서는 theta를 크게 근사하였기 때문이다.  \n",
    "\n",
    "실제로 던진 동전을 잘 찾아냈다는 것을 확인할 수 있다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observed data $X=(X_1,X_2,X_3,X_4,X_5)$,  \n",
    "$\\qquad$$X_k\\in{\\{0,1,...,10\\}}$: $k$번째 round에서 나온 H의 개수  \n",
    "latent variable $Z=(Z_1,Z_2,Z_3,Z_4,Z_5)$,  \n",
    "$\\qquad$$Z_k\\in{\\{A,B\\}}$: $k$번째 round에서 던진 동전의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  <center></center> |  <center>A를 던졌을 확률</center> |  <center>B를 던졌을 확률</center> | <center>실제로 던진 동전</center>\n",
    "|:--------|:--------:|--------:|--------:|\n",
    "|**Round 1** | <center>0.097</center> |<center>0.902</center> |<center>B</center> |\n",
    "|**Round 2** | <center>0.953</center> |<center>0.047</center> |<center>A</center> |\n",
    "|**Round 3** | <center>0.845</center> |<center>0.155</center> |<center>A</center> |\n",
    "|**Round 4** | <center>0.028</center> |<center>0.972</center> |<center>B</center> |\n",
    "|**Round 5** | <center>0.596</center> |<center>0.404</center> |<center>A</center> |"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "$\\qquad$ 1. H T T T H H T H T H  \n",
    "$\\qquad$ 2. H H H H T H H H H H  \n",
    "$\\qquad$ 3. H T H H H H H T H H    \n",
    "$\\qquad$ 4. H T H T T T H H T T  \n",
    "$\\qquad$ 5. T H H H T H H H T H  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "![Alt text](Rawresult.png \"title asdasdasdads\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<img width=\"300\" height=\"100\">\n",
    "![Alt text](Rawresult.png \"title asdasdasdads\")\n",
    "</img>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Rawresult.png\" width=\"3\" height=\"2\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "관측할 수 있는 확률변수 $X$, 관측할 수 없는 확률변수 $Z$, 매개변수 $\\theta$가 있을 때, $(X,Z)$에 대한 확률분포(probability distribution)가\n",
    "\n",
    "$\\qquad L(\\theta;X,Z)=p(X,Z|\\theta)$  \n",
    "\n",
    "로 주어져 있을 때, MLE를 계산하고 싶은 경우 likelihood function은 다음과 같이 정의할 수 있다.\n",
    "\n",
    "$\\qquad L(\\theta;X)=p(X|\\theta)=\\sum_{Z}(p(X,Z|\\theta))$  \n",
    "\n",
    "이 수식은 잠재변수(latent variable) $Z$가 취할 수 있는 값의 수에 비례하고, $Z$의 차원이 증가할수록 취할 수 있는 값의 수는 지수적으로 증가하기 때문에 이 수식을 계산하기는 매우 어렵다.  \n",
    "EM algorithm은 다음의 두 단계를 반복하여 likelihood function $L(\\theta;X)$의 MLE를 구한다.\n",
    "\n",
    "E-step: $\\theta^{(t)}$가 주어지며 새로운 $\\theta$를 사용할 때의 ML의 기댓값인 $Q$를 정의한다. 이 때 기댓값을 취하는 확률분포는 $X, \\theta^{(t)}$가 주어졌을 때 $Z$의 조건부 분포이다.\n",
    "\n",
    "$\\qquad Q(\\theta|\\theta^{(t)})=E_{Z|X,\\theta^{(t)}}[logL(\\theta;X,Z)]=\\sum_{Z}p(Z|X,\\theta^{(t)})logL(\\theta;X,Z)$\n",
    "\n",
    "M-step: $Q$를 최대화하는 새로운 parameter $\\theta^{(t+1)}$를 계산한다.\n",
    "\n",
    "$\\qquad Q^{(t+1)}=arg\\max_{\\theta} Q(\\theta|\\theta^{(t)})$\n",
    "\n",
    "EM algorithm은 다양한 모델에 적용 가능하지만, 적용되는 모델은.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
